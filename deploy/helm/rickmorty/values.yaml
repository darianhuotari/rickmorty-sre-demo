image:
  repository: rickmorty-sre-demo    # change to your registry/repo
  tag: latest
  pullPolicy: IfNotPresent

# replicaCount: 2 # don't need a replica count since we have hpa

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: nginx
  annotations: {}
  hosts:
    - host: rickmorty.local    # change for your domain
      paths:
        - path: /
          pathType: Prefix
  tls: []   # e.g., - secretName: rickmorty-tls; hosts: [rickmorty.example.com]

  # NGINX rate limiting (per-client IP by default)
  rateLimit:
    rps: 50                  # requests per second per client
    burst: 100               # token bucket burst
    noDelay: false           # true => serve bursts immediately; false => gently pace
    connections: 20          # concurrent connections per client
    #statusCode: 429          # status code on limit (ingress-nginx supports this)
    key: "$binary_remote_addr"  # rate-limit key (e.g. $binary_remote_addr, $http_x_api_key)

resources:
  limits:
    #cpu: "500m" No CPU limit; not multitenant
    memory: "512Mi"
  requests:
    cpu: "250m"
    memory: "256Mi"

nodeSelector: {}
tolerations: []
affinity: {}

hpa:
  enabled: true
  minReplicas: 2
  maxReplicas: 6
  # Targets are percentages of requested resources
  cpuUtilization: 70
  memoryUtilization: 80

# App configuration
env:
  CACHE_TTL: "300"
  MAX_RETRIES: "5"
  REQUEST_TIMEOUT: "10"
  REFRESH_WORKER_ENABLED: "1"
  REFRESH_INTERVAL: "300"
  LOG_FILE_PATH: "/var/log/app/app.log"  # main container writes to this; sidecar tails it

    # --- DB wait / startup backoff ---
  DB_WAIT_MAX_ATTEMPTS: 10        # how many ping attempts before giving up
  DB_WAIT_BACKOFF_START: 1.0      # seconds (first wait)
  DB_WAIT_BACKOFF_MAX: 10.0       # seconds (cap)

  # --- SQLAlchemy pool tuning (only used for Postgres URLs) ---
  DB_POOL_SIZE: 5                 # base pool size
  DB_MAX_OVERFLOW: 10             # how many extra conns beyond pool_size
  DB_POOL_RECYCLE: 1800           # seconds; proactively recycle idle conns

# Database configuration
database:
  # If you manage secrets yourself (Vault/ExternalSecrets), set existingSecret and key
  existingSecret: ""     # e.g., "rmdb-secret"
  key: "DATABASE_URL"    # the key inside the Secret holding the URL
  # Or have the chart create a Secret from values below (not recommended for real prod)
  createSecret: false
  url: ""                # e.g., "postgresql+asyncpg://rick:rickpass@postgres:5432/rmdb"

# Fluent Bit log sidecar (tail a shared emptyDir and ship to stdout)
fluentbit:
  enabled: true
  image: "cr.fluentbit.io/fluent/fluent-bit:2.1.10"
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi
  # Minimal config: tail the shared file and print to stdout (k8s will collect)
  inputPath: "/var/log/app/app.log"

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 10001
  runAsGroup: 10001
  fsGroup: 10001
  seccompProfile:
    type: RuntimeDefault

containerSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop: ["ALL"]

postgresql:
  enabled: true
  auth:
    username: rick
    password: rickpass
    database: rmdb
  primary:
    persistence:
      enabled: false  # ephemeral for demo; set true with a StorageClass in prod

# If you manage secrets yourself, keep these empty and use existingSecret like before
#database:
#  existingSecret: ""
# key: DATABASE_URL
#  createSecret: false
#  url: ""